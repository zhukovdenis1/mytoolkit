import json
import time
import random
import os
from urllib.parse import unquote
from playwright.sync_api import sync_playwright

COOKIES_FILE = "aliexpress_cookies.json"
MAX_RETRIES = 3

def save_cookies(context):
    cookies = context.cookies()
    with open(COOKIES_FILE, 'w') as f:
        json.dump(cookies, f)
    print("‚úì –ö—É–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

def load_cookies(context):
    if os.path.exists(COOKIES_FILE):
        with open(COOKIES_FILE, 'r') as f:
            cookies = json.load(f)
            context.add_cookies(cookies)
        print("‚úì –ö—É–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        return True
    return False

def is_captcha_url(url):
    """–¢–æ—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ URL –∫–∞–ø—á–∏ (—Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω–æ–π URL, –Ω–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)"""
    return "/_____tmd_____/punish" in url

def wait_for_reviews_page(page, timeout=120000):
    """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–∑—ã–≤–æ–≤"""
    print("‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–∑—ã–≤–æ–≤...")
    start_time = time.time()

    while True:
        current_url = page.url
        if time.time() - start_time > timeout:
            raise TimeoutError("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ URL –æ—Ç–∑—ã–≤–æ–≤ –ò –ù–ï URL –∫–∞–ø—á–∏
        if "/item/1005008081521104/reviews" in current_url and not is_captcha_url(current_url):
            try:
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∏–¥–∏–º–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                page.wait_for_selector("div.reviews-content", timeout=10000)
                print("‚úì –°—Ç—Ä–∞–Ω–∏—Ü–∞ –æ—Ç–∑—ã–≤–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return True
            except:
                print("√ó –ö–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–∑—ã–≤–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–∂–∏–¥–∞–Ω–∏–µ...")

        time.sleep(2)

def parse_reviews():
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=False,
            channel="chrome",
            args=[
                "--start-maximized",
                "--disable-blink-features=AutomationControlled",
                "--disable-infobars",
                "--lang=ru-RU"
            ]
        )

        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            viewport={"width": 1920, "height": 1080},
            locale="ru-RU",
            timezone_id="Europe/Moscow"
        )

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫—É–∫–∏
        load_cookies(context)
        page = context.new_page()

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Referer –∫–∞–∫ –±—É–¥—Ç–æ –ø–µ—Ä–µ—à–ª–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞
        page.set_extra_http_headers({
            "Referer": "https://aliexpress.ru/item/1005008081521104.html"
        })

        # –û—Å–Ω–æ–≤–Ω–æ–π URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–∑—ã–≤–æ–≤
        #reviews_url = "https://aliexpress.ru/item/1005008081521104/reviews?sku_id=12000048377048266"
        reviews_url = "https://aliexpress.ru/item/1005008081521104/reviews"

        try:
            # –ü—Ä—è–º–æ–π –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–∑—ã–≤–æ–≤
            print("üåê –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–∑—ã–≤–æ–≤...")
            page.goto(reviews_url, timeout=60000)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–ø—á–∏ (–µ—Å–ª–∏ –ø–æ—è–≤–∏–ª–∞—Å—å)
            if is_captcha_url(page.url):
                print("\n=== –ù–ï–û–ë–•–û–î–ò–ú–û –†–ï–®–ò–¢–¨ –ö–ê–ü–ß–£ ===")
                print("1. –†–µ—à–∏—Ç–µ –∫–∞–ø—á—É –≤ –æ—Ç–∫—Ä—ã–≤—à–µ–º—Å—è –±—Ä–∞—É–∑–µ—Ä–µ")
                print("2. –î–æ–∂–¥–∏—Ç–µ—Å—å –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–∑—ã–≤–æ–≤")
                print("3. –°–∫—Ä–∏–ø—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
                print("===============================\n")

                # –ñ–¥–µ–º –∫–æ–≥–¥–∞ URL –∏–∑–º–µ–Ω–∏—Ç—Å—è –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π
                wait_for_reviews_page(page)
                save_cookies(context)

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ AJAX-–∑–∞–ø—Ä–æ—Å–æ–≤
            captured_pages = set()

            def handle_response(response):
                if "aer-jsonapi/review" in response.url and response.request.method == "POST":
                    try:
                        # –î–ª—è POST-–∑–∞–ø—Ä–æ—Å–æ–≤
                        post_data = response.request.post_data
                        if post_data:
                            data = json.loads(post_data)
                            page_num = data.get("pagination", {}).get("pageNum", 0)

                            if 1 <= page_num <= 5 and page_num not in captured_pages:
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ —Å–∞–º –∑–∞–ø—Ä–æ—Å, –∏ –æ—Ç–≤–µ—Ç
                                result = {
                                    "request": data,
                                    "response": response.json()
                                }

                                filename = f"reviews_page_{page_num}.json"
                                with open(filename, 'w', encoding='utf-8') as f:
                                    json.dump(result, f, ensure_ascii=False, indent=2)

                                captured_pages.add(page_num)
                                print(f"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}")
                    except Exception as e:
                        print(f"√ó –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

            page.on("response", handle_response)

            # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç–∑—ã–≤–æ–≤
            print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–∫—Ä—É—Ç–∫—É...")
            for attempt in range(1, 31):  # –ú–∞–∫—Å–∏–º—É–º 30 –ø–æ–ø—ã—Ç–æ–∫
                if len(captured_pages) >= 5:
                    break

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –ø–æ–ø–∞–ª–∏ –ª–∏ —Å–Ω–æ–≤–∞ –Ω–∞ –∫–∞–ø—á—É
                if is_captcha_url(page.url):
                    print("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞, —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ—à–µ–Ω–∏–µ")
                    wait_for_reviews_page(page)
                    save_cookies(context)
                    continue

                # –ü–ª–∞–≤–Ω–∞—è –ø—Ä–æ–∫—Ä—É—Ç–∫–∞
                scroll_amount = random.randint(800, 1200)
                page.evaluate(f"""
                    window.scrollBy({{
                        top: {scroll_amount},
                        behavior: 'smooth'
                    }});
                """)

                # –°–ª—É—á–∞–π–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –º—ã—à–∏
                if random.random() > 0.5:
                    page.mouse.move(
                        random.randint(100, 500),
                        random.randint(100, 500)
                    )

                # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                delay = random.uniform(2.0, 4.0)
                time.sleep(delay)
                print(f"‚Üª –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ {attempt}, —Å–æ–±—Ä–∞–Ω–æ: {len(captured_pages)}/5")

            print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ–±—Ä–∞–Ω–æ {len(captured_pages)} —Å—Ç—Ä–∞–Ω–∏—Ü –æ—Ç–∑—ã–≤–æ–≤")

        except Exception as e:
            print(f"√ó –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        finally:
            save_cookies(context)
            time.sleep(2)
            browser.close()

if __name__ == "__main__":
    parse_reviews()
